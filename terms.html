<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chat LLM â€” Terms of Use</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: #0d0b22;
            color: #ffffff;
            padding: 20px;
            line-height: 1.6;
            max-width: 700px;
            margin: auto;
        }
        h1, h2 {
            color: #cfcfff;
        }
        a {
            color: #89b4ff;
        }
    </style>
</head>
<body>
<h1>Terms of Use for Chat LLM</h1>
<p><strong>Last updated: 23 December 2025</strong></p>
<p>
These Terms of Use ("Terms") govern your use of the Chat LLM application ("the App"),
developed and maintained by <strong>David Picknell</strong> ("we", "us", "our"). By using the App,
you agree to be bound by these Terms. If you do not agree, you should stop using the App.
</p>
<p>
Useful links:<br>
- <a href="index.html">Support Page</a><br>
- <a href="privacy-policy.html">Privacy Policy</a>
</p>

<h2>1. Description of the Service</h2>
<p>
Chat LLM provides three ways to interact with AI:
</p>
<p>
<strong>Built-in Local Model:</strong> The App includes a built-in local AI model (Llama 3.2 1B) that runs 
entirely on your device and works completely offline. No account, API key, or internet connection is required 
to use the local model.
</p>
<p>
<strong>Cloud Inference:</strong> The App offers a free cloud-based AI option (Llama 3.1 8B) that does not 
require an API key. This service is subject to shared usage limits across all users and requires an internet 
connection. Cloud inference is text-only and does not support image or document uploads.
</p>
<p>
<strong>Bring Your Own API Key:</strong> The App optionally allows you to connect your own API keys to interact 
with additional AI models provided by third-party services such as OpenRouter and OpenAI. When using cloud models 
with your own API keys, the App sends your text, images, and documents to these providers' APIs and displays the 
responses returned. We do not operate or control the third-party models.
</p>

<h2>2. User Responsibilities</h2>
<p>
You agree that you will not use the App to:
</p>
<ul>
    <li>Upload or generate content that is illegal, harmful, or abusive;</li>
    <li>Violate intellectual property rights or privacy rights of others;</li>
    <li>Submit sensitive personal data of others without consent;</li>
    <li>Misuse, overload, or attempt to interfere with cloud inference services or third-party AI services;</li>
    <li>Attempt to circumvent usage limits or rate limits;</li>
    <li>Use the service for commercial purposes that violate third-party terms of service.</li>
</ul>

<h2>3. Third-Party Services</h2>
<p>
When you use cloud inference or cloud models with your own API keys, the App relies on APIs provided by 
third parties, including but not limited to Groq, OpenRouter, and OpenAI. Your use of those services is 
also governed by their own terms and privacy policies, which you are responsible for reviewing:
</p>
<ul>
    <li>Groq: <a href="https://groq.com/privacy-policy/">https://groq.com/privacy-policy/</a></li>
    <li>OpenRouter: <a href="https://openrouter.ai/privacy">https://openrouter.ai/privacy</a></li>
    <li>OpenAI: <a href="https://openai.com/policies/row-privacy-policy/">https://openai.com/policies/row-privacy-policy/</a></li>
</ul>
<p>
We are not responsible for the availability, performance, or behaviour of these third-party services.
This section does not apply when using the built-in local model, as no third-party services are involved.
</p>

<h2>4. Cloud Inference Usage Limits</h2>
<p>
The free cloud inference option is subject to shared usage limits across all users. We reserve the right to:
</p>
<ul>
    <li>Implement rate limits or daily request caps;</li>
    <li>Temporarily suspend or restrict access during periods of high demand;</li>
    <li>Modify or discontinue the cloud inference service at any time.</li>
</ul>
<p>
We are not obligated to provide cloud inference service and make no guarantees regarding its availability or performance.
</p>

<h2>5. No Guarantee of AI Output</h2>
<p>
AI-generated responses from the local model, cloud inference, and cloud models with your own API keys may be inaccurate, 
incomplete, or inappropriate. We do not guarantee the correctness, reliability, or suitability of any output produced
by any AI model. You are responsible for how you use and interpret AI output.
</p>

<h2>6. Limitation of Liability</h2>
<p>
To the fullest extent permitted by law, we are not liable for:
</p>
<ul>
    <li>Any loss or damage arising from your reliance on AI-generated content;</li>
    <li>Service interruptions, rate limits, or unavailability of cloud inference or third-party providers;</li>
    <li>Loss or exposure of content sent to cloud inference or third-party services;</li>
    <li>Indirect, incidental, or consequential damages of any kind.</li>
</ul>

<h2>7. Termination</h2>
<p>
We may suspend or restrict your access to the App, including cloud inference services, if we reasonably believe 
you are misusing it or violating these Terms. You may stop using the App at any time by uninstalling it from your devices.
</p>

<h2>8. Changes to These Terms</h2>
<p>
We may update these Terms from time to time. The latest version will always be available on this page.
Continued use of the App after changes are posted means you accept the updated Terms.
</p>

<h2>9. Contact</h2>
<p>
If you have any questions about these Terms, please contact:<br>
<strong>Email:</strong> <a href="mailto:ferrraridave@icloud.com">ferrraridave@icloud.com</a>
</p>
</body>
</html>
