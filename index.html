<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chat LLM — Support</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: #0d0b22;
            color: #ffffff;
            padding: 20px;
            line-height: 1.6;
            max-width: 700px;
            margin: auto;
        }
        h1, h2, h3 {
            color: #cfcfff;
        }
        a {
            color: #89b4ff;
        }
    </style>
</head>
<body>
<h1>Chat LLM — Support</h1>
<p>
If you need help with the Chat LLM app, model configuration, API keys, or any other issue,
you can contact support directly at:<br>
<strong>Email:</strong> <a href="mailto:ferrraridave@icloud.com">ferrraridave@icloud.com</a>
</p>
<p>
Useful links:<br>
- <a href="privacy-policy.html">Privacy Policy</a><br>
- <a href="terms.html">Terms of Use</a>
</p>

<h2>Frequently Asked Questions</h2>

<h3>What is Chat LLM?</h3>
<p>
Chat LLM is a privacy-focused AI chat app for iPhone and iPad with multiple AI options: built-in local model, 
cloud inference, or bring your own API key for access to 300+ additional models.
</p>

<h3>Do I need an account or API key?</h3>
<p>
No. The app includes two options that work without any account or API key:<br><br>
<strong>Built-in Local Model:</strong> Llama 3.2 1B runs completely offline on your device with no internet required.<br><br>
<strong>Cloud Inference:</strong> Fast cloud-based AI (Llama 3.1 8B) available without an API key, subject to shared usage limits.<br><br>
If you want access to advanced cloud models like GPT-4, Claude, or Gemini, you can optionally add your own 
OpenRouter or OpenAI API keys.
</p>

<h3>What models are supported?</h3>
<p>
<strong>Built-in Local Model:</strong> Llama 3.2 1B runs locally on your device with complete privacy. Text-only.<br><br>
<strong>Cloud Inference:</strong> Llama 3.1 8B provides fast cloud responses without requiring an API key. Text-only.<br><br>
<strong>Optional Cloud Models (BYOK):</strong> When you add your own API keys, Chat LLM supports 300+ OpenRouter 
and OpenAI models, including text and vision models. Image and document uploads are only available with vision-capable models.
</p>

<h3>How is my data handled?</h3>
<p>
<strong>Local Model:</strong> When using the built-in local model, all conversations remain on your device.
No data is transmitted anywhere, and the app works completely offline.<br><br>
<strong>Cloud Inference:</strong> When using the free cloud inference option, your messages are sent to our backend 
server which forwards them to the AI provider. We do not store your conversations.<br><br>
<strong>Cloud Models (BYOK):</strong> When using cloud models with your own API keys, your prompts, images,
and documents are sent directly to the AI provider you selected (OpenRouter or OpenAI). Chat LLM does not 
store your prompts or uploads on our servers. For details on how cloud providers handle data, please refer 
to their privacy policies.
</p>

<h3>Can I use the app offline?</h3>
<p>
Yes. The built-in local model works completely offline with no internet connection required.
Cloud inference and cloud models with API keys require an internet connection.
</p>

<h3>Why can't I upload images or documents?</h3>
<p>
Image and document uploads are only available when using vision-capable models via your own API key. 
The built-in local model and free cloud inference option support text-only conversations.
</p>

<h3>What devices are supported?</h3>
<p>
Chat LLM is a universal app optimized for both iPhone and iPad running iOS 17.0 or later.
</p>

<h3>How do I report a bug?</h3>
<p>
Please email a description of the problem and, if possible, include screenshots or steps to reproduce it.<br>
<strong>Email:</strong> <a href="mailto:ferrraridave@icloud.com">ferrraridave@icloud.com</a>
</p>
</body>
</html>
