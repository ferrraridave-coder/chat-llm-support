<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chat LLM & LLM Pro — Privacy Policy</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: #0d0b22;
            color: #ffffff;
            padding: 20px;
            line-height: 1.6;
            max-width: 700px;
            margin: auto;
        }

        h1,
        h2 {
            color: #cfcfff;
        }

        a {
            color: #89b4ff;
        }
    </style>
</head>
<body>

    <h1>Privacy Policy for Chat LLM and LLM Pro</h1>

    <p><strong>Last updated: 12 January 2026</strong></p>

    <p>
        Chat LLM and LLM Pro are developed and maintained by <strong>David Picknell</strong> ("we", "us", "our").
        This Privacy Policy explains how these apps handle your data and what information is transmitted
        to external services.
    </p>

    <p>
        Useful links:<br>
        - <a href="index.html">Support Page</a><br>
        - <a href="terms.html">Terms of Use</a>
    </p>

    <h2>1. Built-in Local AI Model (Chat LLM Only)</h2>

    <p>
        Chat LLM includes a built-in local AI model (Llama 3.2 1B) that runs entirely on your device.
        When using the local model:
    </p>

    <ul>
        <li>All conversations remain on your device</li>
        <li>No data is transmitted to any external servers</li>
        <li>The app works completely offline</li>
        <li>No account or API key is required</li>
        <li>Your prompts and responses are stored locally on your device only</li>
    </ul>

    <p>
        <strong>We do not have access to any conversations you have with the local model.</strong>
        This feature is only available in Chat LLM. LLM Pro operates exclusively via cloud-based APIs.
    </p>

    <h2>2. Cloud Inference (Free Option)</h2>

    <p>
        Both Chat LLM and LLM Pro offer free cloud inference options that do not require an API key.
        When using cloud inference:
    </p>

    <ul>
        <li>Your text prompts are sent to our backend server</li>
        <li>Our server forwards requests to the AI provider (Groq)</li>
        <li>Responses are returned to your device</li>
        <li>No account or API key is required</li>
        <li>Subject to shared usage limits across all users</li>
    </ul>

    <p>
        <strong>We do not store your prompts or responses.</strong>
        Messages are processed in real-time and discarded after delivery.
        Cloud inference is text-only and does not support image or document uploads.
    </p>

    <h2>3. Premium Subscription (LLM Pro Only)</h2>

    <p>
        LLM Pro offers a premium subscription (£9.99 per month) providing access to 8 curated AI models.
        When using premium subscription models:
    </p>

    <ul>
        <li>Your text prompts are sent to our backend server</li>
        <li>Our server forwards requests to Groq</li>
        <li>Responses are returned to your device</li>
        <li>
            Four models (Llama 4 Scout, Llama 4 Maverick, Qwen 3 32B, Kimi K2)
            include real-time web search
        </li>
        <li>
            When web search is invoked, your query is sent to search providers
            to retrieve current information
        </li>
        <li>Subscription is managed through Apple's App Store</li>
    </ul>

    <p>
        <strong>We do not store your prompts or responses.</strong>
        Messages are processed in real-time and discarded after delivery.
        The thinking box feature (which displays AI reasoning) operates locally
        in the app and does not transmit additional data.
    </p>

    <h2>4. Voice Chat (Optional)</h2>

    <p>
        Both Chat LLM and LLM Pro offer real-time voice conversation powered by Grok's speech API.
        This feature requires you to provide your own xAI API key obtained from
        <a href="https://x.ai" target="_blank">x.ai</a>.
        When using voice chat:
    </p>

    <ul>
        <li>Your voice input is transmitted directly to xAI (Grok)</li>
        <li>Audio is processed in real-time for speech recognition and AI response generation</li>
        <li>Conversation transcripts are generated and stored locally on your device</li>
        <li>Your xAI API key is stored only on your device and never transmitted to our servers</li>
    </ul>

    <p>
        <strong>Neither app stores your voice data or conversation transcripts on our servers.</strong>
        All voice processing is handled directly by xAI, and transcripts are saved only on your device.
        Voice chat is text-only and does not support image or document uploads.
    </p>

    <h2>5. Bring Your Own API Key (Advanced Option)</h2>

    <p>
        Both apps optionally allow you to connect your own API keys to access additional
        cloud-based AI models through third-party providers:
    </p>

    <ul>
        <li><strong>Chat LLM:</strong> OpenRouter, OpenAI, and xAI</li>
        <li><strong>LLM Pro:</strong> OpenRouter, OpenAI, and xAI</li>
    </ul>

    <p>If you choose to use your own API keys, you may input and upload:</p>

    <ul>
        <li>Text prompts</li>
        <li>Images (vision-capable models only)</li>
        <li>Documents (vision-capable models only)</li>
        <li>Voice input (xAI voice chat only)</li>
    </ul>

    <p>
        This content is transmitted directly from your device to the third-party AI provider
        you have selected. Neither app stores your prompts, images, documents, or voice data
        on its own servers. Your API keys are stored only on your device and are never
        transmitted to our servers.
    </p>

    <h2>6. How Your Data Is Used</h2>

    <p><strong>Local Model (Chat LLM only):</strong></p>

    <p>
        When using the built-in local model, all processing happens on your device.
        No data leaves your device, and we have no access to your conversations.
    </p>

    <p><strong>Cloud Inference (Both Apps):</strong></p>

    <p>
        When using free cloud inference options, your text prompts are transmitted
        through our backend server to the AI provider. We do not store, log, or retain
        your prompts or responses. All processing is real-time only.
    </p>

    <p><strong>Premium Subscription (LLM Pro only):</strong></p>

    <p>
        When using premium subscription models, your text prompts are transmitted
        through our backend server to Groq. When using models with web search,
        your queries may be sent to search providers to retrieve current information.
        We do not store, log, or retain your prompts or responses.
    </p>

    <p><strong>Voice Chat (Both Apps):</strong></p>

    <p>
        When using voice chat, your voice input and conversations are transmitted
        directly to xAI (Grok) for processing. Neither app stores your voice data
        or transcripts on our servers.
    </p>

    <p><strong>Bring Your Own API Key (Both Apps):</strong></p>

    <p>
        When you use cloud models with your own API key, the apps securely transmit
        your content directly to the third-party AI service you select.
    </p>

    <p><strong>Neither app does the following:</strong></p>

    <ul>
        <li>Store your prompts, voice data, or uploaded content</li>
        <li>Store your API keys on our servers</li>
        <li>Create or manage user accounts</li>
        <li>Collect analytics or tracking data</li>
        <li>Sell or share data with advertisers</li>
    </ul>

    <h2>7. Third-Party Data Retention</h2>

    <p>
        While neither app retains your content, third-party providers may store
        or log data in accordance with their own policies:
    </p>

    <ul>
        <li><strong>Groq:</strong> <a href="https://groq.com/privacy-policy/">https://groq.com/privacy-policy/</a></li>
        <li><strong>xAI:</strong> <a href="https://x.ai/legal/privacy-policy/">https://x.ai/legal/privacy-policy/</a></li>
        <li><strong>OpenRouter:</strong> <a href="https://openrouter.ai/privacy">https://openrouter.ai/privacy</a></li>
        <li><strong>OpenAI:</strong> <a href="https://openai.com/policies/row-privacy-policy/">https://openai.com/policies/row-privacy-policy/</a></li>
    </ul>

    <p>
        This does not apply when using Chat LLM's built-in local model,
        as no data leaves your device.
    </p>

    <h2>8. No Tracking or Analytics</h2>

    <p>
        Neither Chat LLM nor LLM Pro includes analytics SDKs, advertising trackers,
        or other third-party tracking tools.
    </p>

    <h2>9. Security</h2>

    <p>
        When using Chat LLM's built-in local model, all data remains on your device.
        When using cloud services, communication is transmitted over HTTPS.
    </p>

    <h2>10. Your Rights</h2>

    <p>
        Because neither app stores personal data on our servers, there is no user
        data held by us to access, export, or delete.
    </p>

    <h2>11. Subscription Management</h2>

    <p>
        LLM Pro's premium subscription is managed entirely through Apple's App Store.
        We do not have access to payment information.
    </p>

    <h2>12. Contact</h2>

    <p>
        <strong>Email:</strong>
        <a href="mailto:ferrraridave@icloud.com">ferrraridave@icloud.com</a>
    </p>

    <h2>13. Changes to This Policy</h2>

    <p>
        We may update this Privacy Policy from time to time.
        Continued use of the apps indicates acceptance of the updated Policy.
    </p>

</body>
</html>
