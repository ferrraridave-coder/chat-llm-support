<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chat LLM â€” Privacy Policy</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, sans-serif;
            background-color: #0d0b22;
            color: #ffffff;
            padding: 20px;
            line-height: 1.6;
            max-width: 700px;
            margin: auto;
        }
        h1, h2 {
            color: #cfcfff;
        }
        a {
            color: #89b4ff;
        }
    </style>
</head>
<body>
<h1>Privacy Policy for Chat LLM</h1>
<p><strong>Last updated: 23 December 2025</strong></p>
<p>
Chat LLM is developed and maintained by <strong>David Picknell</strong> ("we", "us", "our").  
This Privacy Policy explains how the app handles your data and what information is transmitted
to external services.
</p>
<p>
Useful links:<br>
- <a href="index.html">Support Page</a><br>
- <a href="terms.html">Terms of Use</a>
</p>

<h2>1. Built-in Local AI Model</h2>
<p>
Chat LLM includes a built-in local AI model (Llama 3.2 1B) that runs entirely on your device.
When using the local model:
</p>
<ul>
    <li>All conversations remain on your device</li>
    <li>No data is transmitted to any external servers</li>
    <li>The app works completely offline</li>
    <li>No account or API key is required</li>
    <li>Your prompts and responses are stored locally on your device only</li>
</ul>
<p>
<strong>We do not have access to any conversations you have with the local model.</strong>
</p>

<h2>2. Cloud Inference (Free Option)</h2>
<p>
Chat LLM offers a free cloud inference option powered by Llama 3.1 8B that does not require an API key.
When using cloud inference:
</p>
<ul>
    <li>Your text prompts are sent to our backend server</li>
    <li>Our server forwards requests to the AI provider (Groq)</li>
    <li>Responses are returned to your device</li>
    <li>No account or API key is required</li>
    <li>Subject to shared usage limits across all users</li>
</ul>
<p>
<strong>We do not store your prompts or responses.</strong> Messages are processed in real-time and discarded after delivery.
Cloud inference is text-only and does not support image or document uploads.
</p>

<h2>3. Bring Your Own API Key (Advanced Option)</h2>
<p>
Chat LLM optionally allows you to connect your own API keys to access additional cloud-based AI models
through third-party providers such as <strong>OpenRouter</strong> and <strong>OpenAI</strong>.
</p>
<p>
If you choose to use your own API keys, you may input and upload:
</p>
<ul>
    <li>Text prompts</li>
    <li>Images (vision-capable models only)</li>
    <li>Documents (vision-capable models only)</li>
</ul>
<p>
This content is transmitted directly from your device to the third-party AI provider you have selected.
Chat LLM does <strong>not</strong> store your prompts, images, or documents on its own servers.
Your API keys are stored only on your device and are never transmitted to our servers.
</p>

<h2>4. How Your Data Is Used</h2>
<p><strong>Local Model:</strong></p>
<p>
When using the built-in local model, all processing happens on your device. No data leaves your device,
and we have no access to your conversations.
</p>

<p><strong>Cloud Inference:</strong></p>
<p>
When using the free cloud inference option, your text prompts are transmitted through our backend server
to the AI provider. We do not store, log, or retain your prompts or responses. All processing is real-time only.
</p>

<p><strong>Bring Your Own API Key:</strong></p>
<p>
When you use cloud models with your own API key, Chat LLM securely transmits your content directly to
the third-party AI service (OpenRouter or OpenAI, depending on the model you select).
These services process your request and return an AI-generated response, which is displayed in the app.
</p>

<p><strong>Chat LLM does not:</strong></p>
<ul>
    <li>Store your prompts or uploaded content</li>
    <li>Store your API keys on our servers</li>
    <li>Create or manage user accounts</li>
    <li>Collect analytics or tracking data</li>
    <li>Sell or share data with advertisers</li>
</ul>

<h2>5. Third-Party Data Retention</h2>
<p>
While Chat LLM does not retain your content, when using cloud inference or cloud models with your own API keys,
third-party providers may store or log data in accordance with their own policies. You should review those policies
to understand how your data is handled:
</p>
<ul>
    <li><strong>Groq (Cloud Inference):</strong> <a href="https://groq.com/privacy-policy/">https://groq.com/privacy-policy/</a></li>
    <li><strong>OpenRouter:</strong> <a href="https://openrouter.ai/privacy">https://openrouter.ai/privacy</a></li>
    <li><strong>OpenAI:</strong> <a href="https://openai.com/policies/row-privacy-policy/">https://openai.com/policies/row-privacy-policy/</a></li>
</ul>
<p>
By using cloud inference or cloud models in Chat LLM, you acknowledge that any data sent to these providers is subject
to their respective terms and privacy policies. <strong>This does not apply when using the built-in local model,
as no data leaves your device.</strong>
</p>

<h2>6. No Tracking or Analytics</h2>
<p>
Chat LLM does not include analytics SDKs, advertising trackers, or other third-party tracking tools.
We do not build profiles of users or track behaviour across apps or websites.
</p>

<h2>7. Security</h2>
<p>
When using the built-in local model, all data remains on your device with no network transmission.
</p>
<p>
When using cloud inference or cloud models with your own API keys, all communication with AI providers is transmitted
over HTTPS using industry-standard encryption. However, no method of transmission over the internet is entirely risk-free,
and you should avoid sending highly sensitive or confidential information through cloud-based services.
</p>

<h2>8. Your Rights</h2>
<p>
Because Chat LLM does not store personal data or content on our servers, there is no user data held by us
to access, export, or delete. Conversations with the local model are stored only on your device and can be
deleted through the app's interface. Any data sent to third-party cloud providers would be managed according
to their policies, and you would need to contact them directly where applicable.
</p>

<h2>9. Contact</h2>
<p>
If you have any questions or concerns about this Privacy Policy, please contact:<br>
<strong>Email:</strong> <a href="mailto:ferrraridave@icloud.com">ferrraridave@icloud.com</a>
</p>

<h2>10. Changes to This Policy</h2>
<p>
We may update this Privacy Policy from time to time. The latest version will always be available on
this page. Continued use of Chat LLM after changes are posted means you accept the updated Policy.
</p>
</body>
</html>
